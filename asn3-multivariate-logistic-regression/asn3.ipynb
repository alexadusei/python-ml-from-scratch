{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Multivariate Logistic Regression\n",
    "\n",
    "Now that we've finished our logistic regression example, you'll realize that the limitations of it is that it's binary classification\n",
    "\n",
    "In this example, we'll expand our solution to handle multi-class classification. This will set up the first set of the exercise and prepare us for the next topic: neural networks.\n",
    "\n",
    "This task is using logistic regression to recognize written numbers (0-9). We'll start by loading the dataset. The Coursera course uses a MATLAB file *ex3data1.mat*, which pandas can't handle. We'll use a SciPy to load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " '__globals__': [],\n",
       " '__header__': 'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ..., \n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd = os.getcwd()\n",
    "data = loadmat(pwd + '/asn3/data/ex3data1.mat')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review the shapes of the arrays we just loaded into memory\n",
    "data['X'].shape, data['y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Remember what we have here: for our training data X, we have 5000 examples of 20x20 pixel images of handwritten numbers. We unroll our 20x20 pixel images to be one vector of 400 pixels. The measurement here is pixel-intensity in greyscale (so, it's not RGB). That's how we come up with a (5000, 400) dimension set for X\n",
    "\n",
    "The class labels in y represent what digit the handwritten number in X is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Cost Function\n",
    "\n",
    "We can use the same cost function as before because we vectorized it, meaning it's not hardcoded to a certain amount of features. We'll use the exact same one from the previous example. Note that we're jumping straight to the regularized approach here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))  \n",
    "\n",
    "def cost(theta, X, y, reg_lambda):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    h = sigmoid(X * theta.T)\n",
    "    m = len(X)\n",
    "    \n",
    "    # don't regularize the first theta term\n",
    "    reg = (reg_lambda / (2 * m)) * np.sum(np.power(theta[:, 1:], 2))\n",
    "    \n",
    "    return ((1.0 / m) * np.sum(np.multiply(-y, np.log(h)) - np.multiply((1 - y), np.log(1 - h)))) \\\n",
    "        + reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Gradient Descent\n",
    "\n",
    "We'll use gradient descent here as well. This was defined in the previous example with a for loop. We'll implement one without a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient(theta, X, y, reg_lambda):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    m = len(X)\n",
    "\n",
    "    h = compute_hypothesis(X * theta.T)\n",
    "    \n",
    "    reg = ((reg_lambda / m) * theta)\n",
    "\n",
    "    # regularize the whole set\n",
    "    # WARNING 1: in numpy, np.multiply is thought of as matrix multiplication, \n",
    "    # NOT as dot product.\n",
    "\n",
    "    # WARNING 2: in pandas, adding two matrices with different dimensions\n",
    "    # undergoes matrix broadcasting, which will reshape the resulting matrix\n",
    "    # to prevent involuntarily reshaping when adding, always ensure both your\n",
    "    # matrices are the same dimensiosn when adding\n",
    "    grad = ((1.0 / m) * (X.T * (h - y))).T + reg\n",
    "\n",
    "    # update the first term to not be regularized\n",
    "    grad[0, 0] = (1.0 / m) * np.sum(np.multiply(h - y, X[:, 0]))\n",
    "\n",
    "    return grad\n",
    "\n",
    "def gradient_original(theta, X, y, learningRate):  \n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "\n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    error = sigmoid(X * theta.T) - y\n",
    "\n",
    "    grad = ((X.T * error) / len(X)).T + ((learningRate / len(X)) * theta)\n",
    "\n",
    "    # intercept gradient is not regularized\n",
    "    grad[0, 0] = np.sum(np.multiply(error, X[:,0])) / len(X)\n",
    "\n",
    "    return np.array(grad).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that we've defined our cost and gradient functions, we'll build our classifer.\n",
    "\n",
    "For this task, we have 10 possible classes. Since logistic regression's only able to distringuish between 2 classes at a time, we'll use a *one-vs-all classification* approach, where each class we run through does an analysis of *class k* and *not class k*.\n",
    "\n",
    "We'll wrap the classifier training in one function that computes the final weights for each of the 10 classifiers and returns the weights as a *k x (n + 1)* array, where n is the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# think of k (n + 1) as 'for each class, this I am either class k or not\n",
    "# class k. We'l have a 10x10 matrix in this case, where each row represents\n",
    "# the class, and each col will have 9 zeros and one 1 (showing which class\n",
    "# that value of k belongs to)\n",
    "def one_vs_all(X, y, num_labels, reg_lambda):\n",
    "    num_examples = X.shape[0] # 5000\n",
    "    num_features = X.shape[1] # 400\n",
    "    \n",
    "    # k x (n + 1) array for the parameters of each of the k classifiers\n",
    "    # (10, 401) <- 11 due to 'ones' column we'll be adding next\n",
    "    all_theta = np.zeros((num_labels, num_features + 1))\n",
    "    \n",
    "    # insert a column of ones at the beginning for the intercept term\n",
    "    # (5000, 401)\n",
    "    X = np.insert(X, 0, values=np.ones(num_examples), axis=1)\n",
    "    \n",
    "    # labels are 1-indexed instead of 0-indexed\n",
    "    for i in range(1, num_labels + 1):\n",
    "        theta = np.zeros(num_features + 1) # (1, 401)\n",
    "        y_i = np.array([1 if label == i else 0 for label in y]) # (5000, 1)\n",
    "        y_i = np.reshape(y_i, (num_examples, 1))\n",
    "        \n",
    "        # minimize the cost function for each classifier\n",
    "        fmin = minimize(fun=cost, x0=theta, args=(X, y_i, reg_lambda), method='TNC', jac=gradient_original)\n",
    "        all_theta[i-1, :] = fmin.x\n",
    "        \n",
    "    print X.shape, y_i.shape, theta.shape, all_theta.shape\n",
    "        \n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "(5000, 401) (5000, 1) (401,) (10, 401)\n",
      "[[ -4.82623104e+00   0.00000000e+00   0.00000000e+00 ...,   9.14496656e-03\n",
      "    2.88549512e-07   0.00000000e+00]\n",
      " [ -5.81888929e+00   0.00000000e+00   0.00000000e+00 ...,   5.54209611e-02\n",
      "   -6.07966728e-03   0.00000000e+00]\n",
      " [ -8.81931096e+00   0.00000000e+00   0.00000000e+00 ...,  -2.34701067e-04\n",
      "   -1.08823612e-06   0.00000000e+00]\n",
      " ..., \n",
      " [ -1.31276815e+01   0.00000000e+00   0.00000000e+00 ...,  -5.62757888e+00\n",
      "    6.49936790e-01   0.00000000e+00]\n",
      " [ -8.73271923e+00   0.00000000e+00   0.00000000e+00 ...,  -2.88830420e-01\n",
      "    1.99467688e-02   0.00000000e+00]\n",
      " [ -1.31953052e+01   0.00000000e+00   0.00000000e+00 ...,   2.68975933e-04\n",
      "    4.22526177e-05   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print \"Training...\"\n",
    "all_theta = one_vs_all(data['X'], data['y'], 10, 1)\n",
    "print(all_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now we can predict our classes. We're going to compute the class probability for each class, for each training example (using vectorization) and assign the output class label as the class with the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_all(X, all_theta):\n",
    "    num_rows = X.shape[0]\n",
    "    num_features = X.shape[1]\n",
    "    num_labels = all_theta.shape[0]\n",
    "    \n",
    "    # same as before, insert ones\n",
    "    X = np.insert(X, 0, values=np.ones(num_rows), axis=1)\n",
    "    \n",
    "    # convert to matrices\n",
    "    X = np.matrix(X)\n",
    "    all_theta = np.matrix(all_theta)\n",
    "    \n",
    "    # compute the class probability for each class on each training example\n",
    "    h = sigmoid(X * all_theta.T)\n",
    "    \n",
    "    # create array of the index with maximum probability\n",
    "    h_argmax = np.argmax(h, axis=1)\n",
    "    \n",
    "    # because our array was zero-indexed, we need to add one for the true\n",
    "    # label prediction\n",
    "    h_argmax = h_argmax + 1\n",
    "    \n",
    "    return h_argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now we can use this function to generate class predictions for each example to see how well our classifier works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.48%\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_all(data['X'], all_theta)\n",
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, data['y'])]\n",
    "accuracy = (sum(map(int, correct))/ float(len(correct)))\n",
    "\n",
    "print 'Accuracy = {0}%'.format(accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
